## This Sumbmission in a nutshell
"Stand on the shoulders of gigants" (particularly when cognitively depleted, compute deprived, and time constrained)

[Live development of this submission. ](https://otter.ai/u/9SEDvIN5_9eOqE0CYyAFFm_wrXs?utm_source=copy_url)Reccommend you only watch the first 3 mins and last 3 mins (lost in the middle like üòâ)
# Task 1
## Response
(RESPONSE GENERATED BY kapa.ai, If this does not resolve your problem please dont hesitate to reply again with more details and a member of the weaviate team will be happy to help)

Yes, Weaviate does support multimodal search. It allows you to store data objects and vector embeddings from your favorite ML-models. You can use additional modalities such as images, audio, or video as the query, and retrieve corresponding, compatible objects. Some modules, such as multi2vec-clip and multi2vec-bind allow you to search across modalities. For example, you can search for images using a text query, or search for text using an image query [\[source\]](https://weaviate.io/developers/weaviate/api/graphql/search-operators#multimodal-search).
Weaviate also supports image, or multimodal data and performs the same type of ‚Äúnear image‚Äù search across a vector space [\[source\]](https://weaviate.io/blog/find-waldo-with-weaviate#weaviate-is-multimodal).
To get started with Weaviate, you can check out the [Quickstart tutorial](https://weaviate.io/developers/weaviate/quickstart), or build amazing apps with a free trial of [Weaviate Cloud (WCD)](https://console.weaviate.cloud/) [\[source\]](https://weaviate.io/blog/multimodal-rag#ready-to-start-building).
For a more practical approach, you can follow the steps in the Weaviate Academy's guide on working with multimodal data. It includes units on setting up a local Weaviate instance, populating the database, performing searches, and using large language models to augment and transform retrieved data [\[source\]](https://weaviate.io/developers/academy/py/starter_multimodal_data#-units).
Here is an example of how to create a Multimodal Collection in Weaviate:
```py
client.collections.create(  
    name="Animals",  
    vectorizer_config=wvc.config.Configure.Vectorizer.multi2vec_bind(  
        audio_fields=["audio"],  
        image_fields=["image"],  
        video_fields=["video"],  
    )  
)  
```
[\[source\]](https://weaviate.io/blog/multimodal-rag#any-to-any-search)
And here is an example of how to perform an image search:
```py
response = animals.query.near_image(  
    near_image=toBase64("./test/test-cat.jpg"),  
    return_properties=['name','path','mediaType'],  
    limit=3  
)
```  
[\[source\]](https://weaviate.io/blog/multimodal-rag#step-3-performing-image-search--)
I hope this helps you get started with implementing multimodal RAG into your product using Weaviate!
## Tickets
- Create a Reddit app to interface kapa.ai into Weaviate's supreddit by listening to posts (at least). If sufficiently robust extending the kapa.ai app to Reddit should be trivial.

## Task 2
```txt
Weaviate: 1, Waldo: 0 üèÜ Our vector database just beat Jonathan's kid at finding Waldo! Learn form how this fun experiment showcases the power of AI in complex image analysis using @weaviate_io.
https://weaviate.io/blog/find-waldo-with-weaviate
#Weaviate #AIphoto #GenerativeAI
```
![Weaviate waldo champ meme](/imgs/meme.png)

## Expanding
Create an interactive experience for this use case where we deploy the app that does this and we tap into the X api to listen to replies from users where they can reply to the post with an "Where's Waldo" landscape image and the X bot replies with the relative location of Waldo (although this is pretty time consuming I would imagine it would result in a unforgettable experience for X users).
```txt
Ready to challenge Weaviate's Waldo-finding skills? üïµÔ∏è‚Äç‚ôÇÔ∏èüîç Reply to this tweet with your toughest 'Where's Waldo?' image, and our AI will try to spot him! #WaldoAIChallenge #WeaviateVision
```
X user responds with:
```txt
Here
[IMAGE]
```
Waldo X Bot replies with:
```txt
Waldo is found at normalized X coordinate .9 and normalized Y coordinate .2
[IMAGE_SECTION_OF_WALDO_FROM_USER_IMAGE]
``` 
### Tickets
- Create the aforementioned app


## Task 3
![RAG example Diagram](/imgs/diagram.png)
Base diagram src: https://mindfulmatrix.substack.com/p/build-a-simple-llm-application-with